{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kLqgD7un5dq",
    "tags": [
     "description",
     "header"
    ]
   },
   "source": [
    "# Universidade Federal do ABC - UFABC\n",
    "## Centro de Matemática, Computação e Cognição - CMCC\n",
    "\n",
    "## Disciplina: Visão Computacional e Processamento de Imagens\n",
    "\n",
    "Responsável: Prof. Dr. Francisco Zampirolli\n",
    "\n",
    "Estudante: [Bruno Aristimunha](https://github.com/bruAristimunha).\n",
    "\n",
    "Santo André, Terceiro Quadrimestre de 2019\n",
    "\n",
    "### Projeto Final da Disciplina\n",
    "\n",
    "#### Classificação de Grão de Pólen.\n",
    "\n",
    "## Definição do Problema\n",
    "\n",
    "Os grãos de pólen são importantes marcadores geológicos e geográficos presentes em todo o globo. Suas aplicações são diversas, mas dentre as mais comuns podemos citar o uso para a perícia investigativa, o mapeamento do clima em função de milhares de anos e estudos alérgicos, além da produção de alimentos à base de mel. Em todas as áreas citadas, para que se obtenha resultados significativos de análises robustas, faz-se necessário o levantamento estatístico da distribuição dos tipos de pólen presentes em uma amostra.\n",
    "\n",
    "Considerando a diversidade, as semelhanças interespécies e características microscópicas, o reconhecimento de cada espécie demanda uma ampla e longa formação botânica. O processo de aquisição está exposto a seguir na Figura 1.\n",
    "![aquisicao](https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/capture-pipeline.png)\n",
    "\n",
    "#### Figura 01: Processo de aquisição dos grãos de pólen. Inicialmente a amostra é capturada em uma lâmina, há ampliação da imagem no microscópio posteriormente, busca-se focalizar o grão e estudar sua morfologia, classificando a espécie.\n",
    "\n",
    "O processo não trivial de aquisição da imagem demanda tempo, custos em materiais, além de técnica e anos de experiência para classificação. Ademais, dependendo do material usado para aquisição pode haver visualizações distintas para a mesma espécie de pólen. A Figura 2 mostra a diferença entre metodologias de captura de imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "uDhxBZcG8eFQ",
    "outputId": "25205755-adef-41f1-f188-ae5727ae648f",
    "tags": [
     "figs-example-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "url1 = \"https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/solvent2.png\"\n",
    "url2 = \"https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/solvent1.png\"\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "image1 = io.imread(url1)\n",
    "image2 = io.imread(url2)\n",
    "\n",
    "plt.subplot(221).imshow(image1)\n",
    "plt.subplot(222).imshow(image2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_MjWOC68c6f",
    "tags": [
     "fig-example-description"
    ]
   },
   "source": [
    "#### Figura 02: A diferença entre solventes gera uma coloração totalmente distinta quando visualizada no microscópio, empecilhos como esses dificultam a generalização da classificação do biólogo.\n",
    "\n",
    "\n",
    "O aprendizado profundo é o conjunto de técnicas comumente utilizadas em visão computacional para busca de\n",
    "representações hierárquicas de dados. Métodos de camadas convolucionais, permitem solucionar inúmeros problemas da visão computacional pela sua invariância translacional e conectividade local. Em outras palavras, empregamos esse conjunto de técnicas para buscar padrões de formação desconhecidos a priori pelo classificador, que só será descoberto durante o aprendizado.\n",
    "\n",
    "## Dados/imagens\n",
    "\n",
    "Será utilizado um banco de imagens de polens nativos do Mato Grosso do Sul. Por se tratar de um objeto de geometria tridimensional, as diferentes angulações influenciam tanto na classificação do especialista quanto em algoritmos tradicionais de classificação, portanto cada grão possui 35 imagens distintas.\n",
    "\n",
    "O conjunto de dados possui [23](http://palinovic.weebly.com/bancos-de-imagens.html) classes balanceadas, com um total de 805 imagens. Técnicas de aumento de dados nas imagens serão largamente empregadas. Optou-se pelo aumento de dados empregando rotações de 45º, traçando um paralelo com a literatura botânica, que emprega rotações de 45º na captura de imagens. Por se tratar de um objeto de geometria tridimensional levantou-se a hipótese de que essas rotações auxiliariam na generalização dos métodos. Será considerada a divisão: treino, validação e teste, sendo 60, 20 e 20 a porcentagem de cada uma de acordo com a quantidade de imagens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "processing"
    ]
   },
   "source": [
    "\n",
    "## Processamento de imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "per_train = 0.6\n",
    "per_test = 0.2\n",
    "per_validation = 0.2\n",
    "seed_split_folder = 42\n",
    "\n",
    "\n",
    "#model\n",
    "img_width, img_height = 299, 299\n",
    "train_data_dir = \"../data/pollen23e_split/train\"\n",
    "validation_data_dir = \"../data/pollen23e_split/validation\"\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "lr=0.0001\n",
    "momentum=0.9\n",
    "\n",
    "#indice do modelo testado\n",
    "indice = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse primeiro momento realizando uma separação do conjunto de dados em "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "train-test-validation"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 801 files [00:00, 5111.12 files/s]\n"
     ]
    }
   ],
   "source": [
    "import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "split_folders.ratio('../data/pollen23e/', output=\"../data/pollen23e_split\", seed=seed_split_folder, ratio=(per_train, per_test, per_validation)) # default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "models-bib"
    ]
   },
   "outputs": [],
   "source": [
    "#Bibliotecas empregadas na análise\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sistema\n",
      "\n",
      "2019-11-06T19:46:01-03:00\n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 5.5.0\n",
      "\n",
      "compiler   : GCC 8.3.0\n",
      "system     : Linux\n",
      "release    : 5.0.0-32-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n",
      "\n",
      "Bibliotecas\n",
      "\n",
      "skimage         0.16.2\n",
      "IPython         5.5.0\n",
      "matplotlib      3.1.1\n",
      "tensorflow_core 2.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca para impressão do versionamento das bibliotecas importadas. Importante para reprodutibilidade do trabalho\n",
    "%load_ext watermark\n",
    "print(\"\\nSistema\\n\")\n",
    "%watermark\n",
    "print(\"\\nBibliotecas\\n\")\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "models"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201, InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, NASNetLarge, NASNetMobile, ResNet101, ResNet101V2, ResNet152, ResNet152V2, ResNet50, ResNet50V2, VGG16, VGG19, Xception\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "models = [DenseNet121, DenseNet169, DenseNet201, InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, NASNetLarge, NASNetMobile, ResNet101, ResNet101V2, ResNet152, ResNet152V2, ResNet50, ResNet50V2, VGG16, VGG19, Xception]\n",
    "models_name =  ['DenseNet121','DenseNet169','DenseNet201','InceptionResNetV2','InceptionV3','MobileNet','MobileNetV2','NASNetLarge','NASNetMobile','ResNet101','ResNet101V2','ResNet152','ResNet152V2','ResNet50','ResNet50V2','VGG16','VGG19','Xception']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "compile_models"
    ]
   },
   "outputs": [],
   "source": [
    "model = models[indice](weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "#Adding custom Layers\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(23, activation=\"softmax\",use_bias=False)(x)\n",
    "# Creating the final model\n",
    "model_final = Model(model.input,predictions)\n",
    "# compile the model\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=lr, momentum=momentum), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "data_augmentation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 23 classes.\n",
      "Found 160 images belonging to 23 classes.\n",
      "Found 161 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "           rotation_range=45,\n",
    "           width_shift_range=0.1,\n",
    "           height_shift_range=0.1,\n",
    "           shear_range=0.01,\n",
    "           zoom_range=[0.9,1.25],\n",
    "           horizontal_flip=True,\n",
    "           vertical_flip=True,\n",
    "           fill_mode='reflect',\n",
    "           data_format='channels_last',\n",
    "           brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        '../data/pollen23e_split/train',\n",
    "                        target_size = (img_height, img_width),\n",
    "                        batch_size = batch_size,\n",
    "                        save_to_dir = '../data/pollen23e_aug/train',\n",
    "                        save_prefix='aug', \n",
    "                        save_format='png',\n",
    "                        class_mode = \"categorical\",\n",
    "                        seed = 45)\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                        '../data/pollen23e_split/val',\n",
    "                        target_size = (img_height, img_width),\n",
    "                        batch_size = batch_size,\n",
    "                        class_mode = \"categorical\",\n",
    "                        save_to_dir = '../data/pollen23e_aug/train',\n",
    "                        save_prefix='aug', \n",
    "                        save_format='png',\n",
    "                        seed = 45)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                        '../data/pollen23e_split/test',\n",
    "                        target_size = (img_height, img_width),\n",
    "                        batch_size = batch_size,\n",
    "                        class_mode = 'categorical',\n",
    "                        save_to_dir = '../data/pollen23e_aug/train',\n",
    "                        save_prefix='aug', \n",
    "                        save_format='png',\n",
    "                        seed = 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "model_checkpoint"
    ]
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"checkpoints/\"+models_name[indice], \n",
    "                             monitor='val_acc', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', save_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "train_model"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1106 19:46:20.864938 140051437492032 callbacks.py:990] Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/30 [>.............................] - ETA: 4:46 - loss: 3.4349 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 19:46:29.094327 140051437492032 callbacks.py:990] Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/30 [=>............................] - ETA: 4:13 - loss: 3.3951 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 19:46:37.639474 140051437492032 callbacks.py:990] Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/30 [==>...........................] - ETA: 4:00 - loss: 3.4506 - accuracy: 0.0417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 19:46:46.015789 140051437492032 callbacks.py:990] Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/30 [===>..........................] - ETA: 3:47 - loss: 3.3998 - accuracy: 0.0469"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_final.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch = train_generator.samples/batch_size,\n",
    "                epochs = epochs,\n",
    "                callbacks = [checkpoint],\n",
    "                validation_data = validation_generator,\n",
    "                validation_steps = validation_generator.samples/batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.google.com/search?q=reprodutibility+in+computer+science+jupyter&oq=reprodutibility+in+computer+science+jupyter&aqs=chrome..69i57j33.9207j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "\n",
    "https://keras.io/applications/#resnet\n",
    "\n",
    "https://github.com/jupyter-guide/ten-rules-jupyter/blob/e7b184c4949d164ce12eb5fdfbc8c8cd487b8a23/example2/0-Workflow.ipynb\n",
    "\n",
    "https://github.com/nteract/papermill\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "name": "Entrega_0-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
