{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kLqgD7un5dq",
    "tags": [
     "description",
     "header"
    ]
   },
   "source": [
    "# Universidade Federal do ABC - UFABC\n",
    "## Centro de Matemática, Computação e Cognição - CMCC\n",
    "\n",
    "## Disciplina: Visão Computacional e Processamento de Imagens\n",
    "\n",
    "Responsável: Prof. Dr. Francisco Zampirolli\n",
    "\n",
    "Estudante: [Bruno Aristimunha](https://github.com/bruAristimunha).\n",
    "\n",
    "Santo André, Terceiro Quadrimestre de 2019\n",
    "\n",
    "### Projeto Final da Disciplina\n",
    "\n",
    "#### Classificação de Grão de Pólen.\n",
    "\n",
    "## Definição do Problema\n",
    "\n",
    "Os grãos de pólen são importantes marcadores geológicos e geográficos presentes em todo o globo. Suas aplicações são diversas, mas dentre as mais comuns podemos citar o uso para a perícia investigativa, o mapeamento do clima em função de milhares de anos e estudos alérgicos, além da produção de alimentos à base de mel. Em todas as áreas citadas, para que se obtenha resultados significativos de análises robustas, faz-se necessário o levantamento estatístico da distribuição dos tipos de pólen presentes em uma amostra.\n",
    "\n",
    "Considerando a diversidade, as semelhanças interespécies e características microscópicas, o reconhecimento de cada espécie demanda uma ampla e longa formação botânica. O processo de aquisição está exposto a seguir na Figura 1.\n",
    "![aquisicao](https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/capture-pipeline.png)\n",
    "\n",
    "#### Figura 01: Processo de aquisição dos grãos de pólen. Inicialmente a amostra é capturada em uma lâmina, há ampliação da imagem no microscópio posteriormente, busca-se focalizar o grão e estudar sua morfologia, classificando a espécie.\n",
    "\n",
    "O processo não trivial de aquisição da imagem demanda tempo, custos em materiais, além de técnica e anos de experiência para classificação. Ademais, dependendo do material usado para aquisição pode haver visualizações distintas para a mesma espécie de pólen. A Figura 2 mostra a diferença entre metodologias de captura de imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "uDhxBZcG8eFQ",
    "outputId": "25205755-adef-41f1-f188-ae5727ae648f",
    "tags": [
     "figs-example-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "url1 = \"https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/solvent2.png\"\n",
    "url2 = \"https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/solvent1.png\"\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "image1 = io.imread(url1)\n",
    "image2 = io.imread(url2)\n",
    "\n",
    "plt.subplot(221).imshow(image1)\n",
    "plt.subplot(222).imshow(image2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_MjWOC68c6f",
    "tags": [
     "fig-example-description"
    ]
   },
   "source": [
    "#### Figura 02: A diferença entre solventes gera uma coloração totalmente distinta quando visualizada no microscópio, empecilhos como esses dificultam a generalização da classificação do biólogo.\n",
    "\n",
    "\n",
    "O aprendizado profundo é o conjunto de técnicas comumente utilizadas em visão computacional para busca de\n",
    "representações hierárquicas de dados. Métodos de camadas convolucionais, permitem solucionar inúmeros problemas da visão computacional pela sua invariância translacional e conectividade local. Em outras palavras, empregamos esse conjunto de técnicas para buscar padrões de formação desconhecidos a priori pelo classificador, que só será descoberto durante o aprendizado.\n",
    "\n",
    "## Dados/imagens\n",
    "\n",
    "Será utilizado um banco de imagens de polens nativos do Mato Grosso do Sul. Por se tratar de um objeto de geometria tridimensional, as diferentes angulações influenciam tanto na classificação do especialista quanto em algoritmos tradicionais de classificação, portanto cada grão possui 35 imagens distintas.\n",
    "\n",
    "O conjunto de dados possui [23](http://palinovic.weebly.com/bancos-de-imagens.html) classes balanceadas, com um total de 805 imagens. Técnicas de aumento de dados nas imagens serão largamente empregadas. Optou-se pelo aumento de dados empregando rotações de 45º, traçando um paralelo com a literatura botânica, que emprega rotações de 45º na captura de imagens. Por se tratar de um objeto de geometria tridimensional levantou-se a hipótese de que essas rotações auxiliariam na generalização dos métodos. Será considerada a divisão: treino, validação e teste, sendo 60, 20 e 20 a porcentagem de cada uma de acordo com a quantidade de imagens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "processing"
    ]
   },
   "source": [
    "\n",
    "## Processamento de imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "per_train = 0.6\n",
    "per_test = 0.2\n",
    "per_validation = 0.2\n",
    "seed_split_folder = 42\n",
    "\n",
    "\n",
    "#model\n",
    "img_width, img_height = 299, 299\n",
    "train_data_dir = \"../data/pollen23e_split/train\"\n",
    "validation_data_dir = \"../data/pollen23e_split/validation\"\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "#otim\n",
    "lr=0.0001\n",
    "momentum=0.9\n",
    "\n",
    "#data_generate\n",
    "seed = 42\n",
    "\n",
    "\n",
    "\n",
    "#indice do modelo testado\n",
    "indice = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse primeiro momento realizando uma separação do conjunto de dados em "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "train-test-validation"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 801 files [00:01, 657.94 files/s]\n"
     ]
    }
   ],
   "source": [
    "import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "split_folders.ratio('../data/pollen23e/', output=\"../data/pollen23e_split\", seed=seed_split_folder, ratio=(per_train, per_test, per_validation)) # default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "models-bib"
    ]
   },
   "outputs": [],
   "source": [
    "#Bibliotecas empregadas na análise\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sistema\n",
      "\n",
      "2019-11-26T02:33:06-03:00\n",
      "\n",
      "CPython 3.7.4\n",
      "IPython 7.9.0\n",
      "\n",
      "compiler   : GCC 9.2.0\n",
      "system     : Linux\n",
      "release    : 5.3.8-3-MANJARO\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "\n",
      "Bibliotecas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca para impressão do versionamento das bibliotecas importadas. Importante para reprodutibilidade do trabalho\n",
    "%load_ext watermark\n",
    "print(\"\\nSistema\\n\")\n",
    "%watermark\n",
    "print(\"\\nBibliotecas\\n\")\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "models"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201, InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, NASNetLarge, NASNetMobile, ResNet101, ResNet101V2, ResNet152, ResNet152V2, ResNet50, ResNet50V2, VGG16, VGG19, Xception\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "models       = [DenseNet121, DenseNet169, DenseNet201, InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, NASNetLarge, NASNetMobile, ResNet101, ResNet101V2, ResNet152, ResNet152V2, ResNet50, ResNet50V2, VGG16, VGG19, Xception]\n",
    "models_name =  ['DenseNet121','DenseNet169','DenseNet201','InceptionResNetV2','InceptionV3','MobileNet','MobileNetV2','NASNetLarge','NASNetMobile','ResNet101','ResNet101V2','ResNet152','ResNet152V2','ResNet50','ResNet50V2','VGG16','VGG19','Xception']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "data_augmentation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 23 classes.\n",
      "Found 160 images belonging to 23 classes.\n",
      "Found 161 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "           rotation_range=45,\n",
    "           width_shift_range=0.1,\n",
    "           height_shift_range=0.1,\n",
    "           shear_range=0.01,\n",
    "           zoom_range=[0.9,1.25],\n",
    "           horizontal_flip=True,\n",
    "           vertical_flip=True,\n",
    "           fill_mode='reflect',\n",
    "           data_format='channels_last',\n",
    "           brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        '../data/pollen23e_split/train',\n",
    "                        target_size = (img_height, img_width),\n",
    "                        batch_size = batch_size,\n",
    "                        save_to_dir = '../data/pollen23e_aug/train',\n",
    "                        save_prefix='aug', \n",
    "                        save_format='png',\n",
    "                        class_mode = \"categorical\",\n",
    "                        follow_links = True,\n",
    "                        seed = seed)\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                        '../data/pollen23e_split/val',\n",
    "                        target_size = (img_height, img_width),\n",
    "                        batch_size = batch_size,\n",
    "                        class_mode = \"categorical\",\n",
    "                        save_to_dir = '../data/pollen23e_aug/valid',\n",
    "                        save_prefix='aug', \n",
    "                        save_format='png',\n",
    "                        follow_links = True,\n",
    "                        seed = seed)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                        '../data/pollen23e_split/test',\n",
    "                        target_size = (img_height, img_width),\n",
    "                        batch_size = batch_size,\n",
    "                        class_mode = 'categorical',\n",
    "                        save_to_dir = '../data/pollen23e_aug/test',\n",
    "                        save_prefix='aug', \n",
    "                        save_format='png',\n",
    "                        follow_links = True,\n",
    "                        seed = seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "model_checkpoint"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pollen23e  pollen23e_aug  pollen23e_split\r\n"
     ]
    }
   ],
   "source": [
    "#!ls ../data/\n",
    "!rm ../data/pollen23e_aug/train/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "train_model",
     "compile_models"
    ]
   },
   "outputs": [],
   "source": [
    "for enum, model in enumerate(models[:1]):\n",
    "    \n",
    "    # Save the model according to the conditions\n",
    "    checkpoint = ModelCheckpoint(\"checkpoints/\"+models_name[enum], \n",
    "                                 monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                                 save_weights_only=False, mode='auto', save_freq=1)\n",
    "    \n",
    "    model = models[enum](weights     = \"imagenet\", \n",
    "                         include_top = False, \n",
    "                         input_shape = (img_width, img_height, 3))\n",
    "    #Adicionando um camada adicional\n",
    "    \n",
    "    \n",
    "    x = model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(23, activation=\"softmax\",use_bias=False)(x)\n",
    "    \n",
    "    # Camada final\n",
    "    model = Model(model.input,predictions)\n",
    "    # compile the model\n",
    "    model.compile(loss = \"categorical_crossentropy\", \n",
    "                  optimizer = optimizers.SGD(lr=lr, momentum=momentum), \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    \n",
    "    history_acc = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch = train_generator.samples/batch_size,\n",
    "                epochs = epochs,\n",
    "                callbacks = [checkpoint],\n",
    "                validation_data = validation_generator,\n",
    "                validation_steps = validation_generator.samples/batch_size)\n",
    "    \n",
    "    model.save(\"checkpoint_\"+models_name[enum]+\".h5\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.google.com/search?q=reprodutibility+in+computer+science+jupyter&oq=reprodutibility+in+computer+science+jupyter&aqs=chrome..69i57j33.9207j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "\n",
    "https://keras.io/applications/#resnet\n",
    "\n",
    "https://github.com/jupyter-guide/ten-rules-jupyter/blob/e7b184c4949d164ce12eb5fdfbc8c8cd487b8a23/example2/0-Workflow.ipynb\n",
    "\n",
    "https://github.com/nteract/papermill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências\n",
    "\n",
    "- Gonçalves, Ariadne Barbosa, et al. [\"Feature extraction and machine learning for the classification of Brazilian Savannah pollen grains.\"](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157044) PloS one 11.6 (2016): e0157044.\n",
    "\n",
    "- Navares, Ricardo, and José Luis Aznarte. [\"Geographical Imputation of Missing Poaceae Pollen Data via Convolutional Neural Networks.\"](https://www.mdpi.com/2073-4433/10/11/717) Atmosphere 10.11 (2019): 717.\n",
    "\n",
    "- Menad, Hanane, Farah Ben-Naoum, and Abdelmalek Amine. [\"A Thresholding Approach for Pollen Detection in Images Based on Simulated Annealing Algorithm.\"](https://www.igi-global.com/article/a-thresholding-approach-for-pollen-detection-in-images-based-on-simulated-annealing-algorithm/237182) International Journal of Agricultural and Environmental Information Systems (IJAEIS) 10.4 (2019): 18-36.\n",
    "\n",
    "- Gallardo-Caballero, Ramón, et al. [\"Precise Pollen Grain Detection in Bright Field Microscopy Using Deep Learning Techniques.\"](https://www.mdpi.com/1424-8220/19/16/3583) Sensors 19.16 (2019): 3583.\n",
    "\n",
    "- Vizgarra, Cristian G., Informaticas Avanzadas, and Jorge Gotay Sardiñas. [\"Advances in the Classification of Pollen Grains Images Obtained from Honey Samples of Tetragonisca angustula in the Province of Chaco, Argentina.\"](https://ijisrt.com/wp-content/uploads/2019/07/IJISRT19JU564.pdf)\n",
    "\n",
    "- de Geus, André R., et al. [\"Large-scale Pollen Recognition with Deep Learning.\"](https://ieeexplore.ieee.org/abstract/document/8902735) 2019 27th European Signal Processing Conference (EUSIPCO). IEEE, 2019.\n",
    "\n",
    "- Allen, G. P., et al. [\"Machine vision for automated optical recognition and classification of pollen grains or other singulated microscopic objects.\"](https://ieeexplore.ieee.org/abstract/document/4749537/) 2008 15th International Conference on Mechatronics and Machine Vision in Practice. IEEE, 2008.\n",
    "\n",
    "- Menad, Hanane, Ben-Naoum, Farah, & Amine, Abdelmalek (2019). [\"Deep Convolutional Neural Network for Pollen Grains Classification\"](http://ceur-ws.org/Vol-2351/paper_34.pdf). In _JERI_.\n",
    "\n",
    "- Nguyen, Nhat Rich, Matina Donalson-Matasci, and Min C. Shin. [\"Improving pollen classification with less training effort.\"](https://ieeexplore.ieee.org/abstract/document/6475049/) 2013 IEEE Workshop on Applications of Computer Vision (WACV). IEEE, 2013.\n",
    "\n",
    "- Sevillano, Víctor, and José L. Aznarte. [\"Improving classification of pollen grain images of the POLEN23E dataset through three different applications of deep learning convolutional neural networks.\"](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201807) PloS one 13.9 (2018): e0201807.\n",
    "\n",
    "- Oteros, J., et al. [\"Year clustering analysis for modelling olive flowering phenology.\"](https://link.springer.com/article/10.1007/s00484-012-0581-3) International journal of biometeorology 57.4 (2013): 545-555.\n",
    "\n",
    "- Holt, K., et al. [\"Progress towards an automated trainable pollen location and classifier system for use in the palynology laboratory.\"](https://www.sciencedirect.com/science/article/pii/S0034666711001205) Review of Palaeobotany and Palynology 167.3-4 (2011): 175-183.\n",
    "\n",
    "- Valan, Miroslav, et al. [\"Automated Taxonomic Identification of Insects with Expert-Level Accuracy Using Effective Feature Transfer from Convolutional Networks.\"](https://academic.oup.com/sysbio/article/68/6/876/5368535) Systematic biology (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "bibtex"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "name": "Entrega_0-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
