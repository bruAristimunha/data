{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kLqgD7un5dq",
    "tags": [
     "Descrição",
     "Cabeçalho"
    ]
   },
   "source": [
    "# Universidade Federal do ABC - UFABC\n",
    "## Centro de Matemática, Computação e Cognição - CMCC\n",
    "\n",
    "## Disciplina: Visão Computacional e Processamento de Imagens\n",
    "\n",
    "Responsável: Prof. Dr. Francisco Zampirolli\n",
    "\n",
    "Estudante: [Bruno Aristimunha](https://github.com/bruAristimunha).\n",
    "\n",
    "Santo André, Terceiro Quadrimestre de 2019\n",
    "\n",
    "### Projeto Final da Disciplina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Problema"
    ]
   },
   "source": [
    "# Classificação de Grão de Pólen.\n",
    "\n",
    "## Introdução <a id='introducao'></a>\n",
    "\n",
    "Os grãos de pólen são importantes marcadores geológicos e geográficos presentes em todo o globo. Suas aplicações são diversas, mas dentre as mais comuns podemos citar o uso para a perícia investigativa, o mapeamento do clima em função de milhares de anos e estudos alérgicos, além da produção de alimentos à base de mel. Em todas as áreas citadas, para que se obtenha resultados significativos de análises robustas, faz-se necessário o levantamento estatístico da distribuição dos tipos de pólen presentes em uma amostra.\n",
    "\n",
    "Considerando a diversidade, as semelhanças interespécies e características microscópicas, o reconhecimento de cada espécie demanda uma ampla e longa formação botânica. O processo de aquisição está exposto a seguir na Figura 1.\n",
    "![aquisicao](https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/capture-pipeline.png)\n",
    "#### Figura 01: Processo de aquisição dos grãos de pólen. Inicialmente a amostra é capturada em uma lâmina, há ampliação da imagem no microscópio posteriormente, busca-se focalizar o grão e estudar sua morfologia, classificando a espécie.\n",
    "\n",
    "O processo não trivial de aquisição da imagem demanda tempo, custos em materiais, além de técnica e anos de experiência para classificação. Ademais, dependendo do material usado para aquisição pode haver visualizações distintas para a mesma espécie de pólen. A Figura 2 mostra a diferença entre metodologias de captura de imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "uDhxBZcG8eFQ",
    "outputId": "25205755-adef-41f1-f188-ae5727ae648f",
    "tags": [
     "Figura-02-diferenças"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "url1 = \"https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/solvent2.png\"\n",
    "url2 = \"https://raw.githubusercontent.com/bruAristimunha/pollenData/master/figs/solvent1.png\"\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "image1 = io.imread(url1)\n",
    "image2 = io.imread(url2)\n",
    "\n",
    "plt.subplot(221).imshow(image1)\n",
    "plt.subplot(222).imshow(image2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figura 02: A diferença entre solventes gera uma coloração totalmente distinta quando visualizada no microscópio, empecilhos como esses dificultam a generalização da classificação do biólogo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "O restante desse texto é organizado como segue. Na Seção [2](#Trabalhos_Relacionados) nós revisamos a literatura sobre a classificação de grão de pólen, com apanhando histórico até os trabalhos mais recentes. Na Seção [3](#Metodologia) nós descrevemos a metodologia proposta que foi empregada. Então, na Seção [4](#Resultados) nós discutimos os discutimos encontrados com a literatura. Considerações e trabalhos futuros estão contidos na Seção [5](#Conclusao).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Trabalhos_Relacionados"
    ]
   },
   "source": [
    "## Trabalho Relacionados <a id='Trabalhos_Relacionados'></a>\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_MjWOC68c6f",
    "tags": [
     "Metodologia"
    ]
   },
   "source": [
    "## Metodologia <a id='Metodologia'></a>\n",
    "\n",
    "O aprendizado profundo é o conjunto de técnicas comumente utilizadas em visão computacional para busca de\n",
    "representações hierárquicas de dados. Métodos de camadas convolucionais, permitem solucionar inúmeros problemas da visão computacional pela sua invariância translacional e conectividade local. Em outras palavras, empregamos esse conjunto de técnicas para buscar padrões de formação desconhecidos a priori pelo classificador, que só será descoberto durante o aprendizado.\n",
    "\n",
    "## Dados/imagens\n",
    "\n",
    "Será utilizado um banco de imagens de polens nativos do Mato Grosso do Sul. Por se tratar de um objeto de geometria tridimensional, as diferentes angulações influenciam tanto na classificação do especialista quanto em algoritmos tradicionais de classificação, portanto cada grão possui 35 imagens distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "models-bib"
    ]
   },
   "outputs": [],
   "source": [
    "#Divisão do Conjunto de Imagem\n",
    "import split_folders\n",
    "\n",
    "#Bibliotecas empregadas na análise\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "#model\n",
    "img_width, img_height = 299, 299\n",
    "#data_generate\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Processamento de imagens\n",
    "\n",
    "\n",
    "IV. MÉTODO PROPOSTO\n",
    "\n",
    "\n",
    "A Figura 1 ilustra as etapas da metodologia proposta para classificação das imagens de grãos de pólen por meio de aprendizado supervisionado. Inicialmente, para cada imagem de um conjunto de dados de grãos de pólen, o processo de extração de recurso é iniciado pela computação de vários descritores de imagem que incluem recursos de baixo nível, como cor e textura. \n",
    "\n",
    "\n",
    "Para este procedimento, Matrizes de Co-Ocorrência de Nível Cinza (GLCM), Padrões Binários Locais (LBP), Correlogramas de Cores Automáticas (ACC) e o Descritor Local de Weber (WLD), que foram detalhados na Seção II, foram usados ​​para gerar um “Banco de dados descritor”. Depois que os descritores são extraídos, o processo de aprendizado da máquina é iniciado. Primeiro, um subconjunto de recursos do conjunto de descritores é escolhido para formar o descritor final de cada imagem do conjunto de dados. Em seguida, o conjunto de dados é dividido em conjuntos de treinamento e teste para o processo de validação cruzada. Para cada conjunto de dados testado neste trabalho, uma validação cruzada de 5 vezes foi aplicada, de tal forma que 80% das imagens (4 dobras) são consideradas como o conjunto de treinamento e a dobra restante (20%) como o conjunto de teste. Essa divisão é feita de tal forma que pelo menos uma amostra de cada classe esteja presente em cada dobra. Depois de dividir o conjunto de dados, o processo de treinamento é iniciado. Aqui, diferentes classificadores de imagem foram treinados separadamente com seus respectivos parâmetros de ajuste. Por sua vez, cada conjunto de parâmetros ótimos foi encontrado executando um procedimento de busca de grade sobre cada espaço respectivo de hiperparâmetros para que a precisão máxima (para um dado conjunto de dados) possa ser obtida para cada classificador. Neste trabalho, foram testados três classificadores: Support Vector Machines (SVM) [57], Random Forests [18] e Logistic Regression [17]. No que diz respeito aos parâmetros ótimos para cada um dos classificadores supracitados, o SVM foi utilizado com um kernel da Função de Base Radial (RBF) com parâmetros C = 10 e γ = 10; para o classificador Random Forests, o número de árvores foi definido em 4200; e para a Regressão Logística, o parâmetro C foi fixado em 10000 junto com o algoritmo de regularização L2. Os classificadores treinados então formam um conjunto, de modo que todos detalhados na Seção II foram usados ​​para gerar um “banco de dados de descritores”. Depois que os descritores são extraídos, o processo de aprendizado da máquina é iniciado. Primeiro, um subconjunto de recursos do conjunto de descritores é escolhido para formar o descritor final de cada imagem do conjunto de dados. Em seguida, o conjunto de dados é dividido em conjuntos de treinamento e teste para o processo de validação cruzada. Para cada conjunto de dados testado neste trabalho, uma validação cruzada de 5 vezes foi aplicada, de tal forma que 80% das imagens (4 dobras) são consideradas como o conjunto de treinamento e a dobra restante (20%) como o conjunto de teste. Essa divisão é feita de tal forma que pelo menos uma amostra de cada classe esteja presente em cada dobra. Depois de dividir o conjunto de dados, o processo de treinamento é iniciado. Aqui, diferentes classificadores de imagem foram treinados separadamente com seus respectivos parâmetros de ajuste. Por sua vez, cada conjunto de parâmetros ótimos foi encontrado executando um procedimento de busca de grade sobre cada espaço respectivo de hiperparâmetros para que a precisão máxima (para um dado conjunto de dados) possa ser obtida para cada classificador. Neste trabalho, foram testados três classificadores: Support Vector Machines (SVM) [57], Random Forests [18] e Logistic Regression [17]. No que diz respeito aos parâmetros ótimos para cada um dos classificadores supracitados, o SVM foi utilizado com um kernel da Função de Base Radial (RBF) com parâmetros C = 10 e γ = 10; para o classificador Random Forests, o número de árvores foi definido em 4200; e para a Regressão Logística, o parâmetro C foi fixado em 10000 junto com o algoritmo de regularização L2. Os classificadores formados formam então um conjunto para que\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados possui [$23$](http://palinovic.weebly.com/bancos-de-imagens.html) imagens de espécies, cada espécie com um total de $35$ registros, totalizando $805$ imagens. Cada espécie de pólen possui uma taxonomia associada, desse modo, para instância possuímos cinco rótulos, sendo eles: classe, ordem, gênero, família e espécie. Ressaltamos que o balanceamento no conjunto ocorre apenas em nível de espécies. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validação do método, em nível de espécie, realizamos a divisão: treino, validação e teste, com as porcentagens: $60$, $20$ e $20$, respectivamente.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "train-test-validation"
    ]
   },
   "source": [
    "per_train = 0.6\n",
    "per_test = 0.2 \n",
    "per_validation = 0.2\n",
    "seed_split_folder = 42\n",
    "\n",
    "split_folders.ratio(input='../data/pollen23e/', \n",
    "                    output=\"../data/pollen23e_split\", \n",
    "                    seed=seed_split_folder, \n",
    "                    ratio=(per_train, per_test, per_validation)) # default values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "data_augmentation"
    ]
   },
   "source": [
    "No conjunto de treino e validação, optou-se pelo aumento de dados empregando rotações de 45º, traçando um paralelo com a literatura botânica, que emprega rotações de 45º na captura de imagens. Além disso, geramos imagens mudando a faixa de altura e largura em uma fração de $10\\%$; usando cisalhamento em $0.1^{\\circ}$ no sentido anti-horário; ampliamos e reduzimos em aleatoriamente entre $\\{0.9, 1.25\\}$; giramos a imagem na horizontal, e na vertical; variamos a intensidade brilho aleatoriamente entre $\\{0.5, 1.5\\}$; e preenchemos eventuais valores faltantes nas figuras com método de reflexão. Por se tratar de um objeto de geometria tridimensional levantou-se a hipótese de que essas transformações auxiliam na generalização dos métodos. Das $480$ imagens de treino obtivemos um total de $6235$ derivadas, no conjunto de validação, das $160$ alcançamos um total de $2240$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rotulo = pd.read_csv('rotulo.csv')\n",
    "columns = rotulo.drop(['caminho','species','split'],1).columns\n",
    "\n",
    "train = rotulo[rotulo['split']=='train/'].drop(\"split\",1)\n",
    "val = rotulo[rotulo['split']=='val/'].drop(\"split\",1)\n",
    "test = rotulo[rotulo['split']=='test/'].drop(\"split\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parametro-aprendizado-profundo"
    ]
   },
   "outputs": [],
   "source": [
    "lr=1E-3\n",
    "momentum= 0.9\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "data_augmentation"
    ]
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "           rotation_range=45,\n",
    "           width_shift_range=0.1,\n",
    "           height_shift_range=0.1,\n",
    "           shear_range=0.01,\n",
    "           zoom_range=[0.9,1.25],\n",
    "           horizontal_flip=True,\n",
    "           vertical_flip=True,\n",
    "           fill_mode='reflect',\n",
    "           data_format='channels_last',\n",
    "           brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "models-description"
    ]
   },
   "source": [
    "### VGG\n",
    "\n",
    "### Xception \n",
    "\n",
    "### Inception \n",
    "\n",
    "### MobileNet\n",
    "\n",
    "### NasNet\n",
    "\n",
    "### ResNet\n",
    "\n",
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "models"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, NASNetMobile, ResNet50, VGG16, VGG19, Xception\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "#DenseNet121, DenseNet169, InceptionResNetV2, InceptionV3, MobileNet,          MobileNetV2,  \n",
    "\n",
    "models = [\n",
    "           ResNet50, \n",
    "          VGG16, VGG19, Xception]\n",
    "#'DenseNet121', 'DenseNet169', InceptionResNetV2', 'InceptionV3', 'MobileNet',\n",
    "               #'MobileNetV2', ,\n",
    "models_name = [\n",
    "               'ResNet50', \n",
    "               'VGG16', 'VGG19', 'Xception']\n",
    "\n",
    "\n",
    "img_width, img_height = 299, 299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferência de Aprendizado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "cleaning-folder"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: rm: Argument list too long\n",
      "mkdir: cannot create directory ‘../data/pollen23e_aug/valid’: File exists\n",
      "mkdir: cannot create directory ‘../data/pollen23e_aug/train’: File exists\n"
     ]
    }
   ],
   "source": [
    "#!ls ../data/\n",
    "!rm ../data/pollen23e_aug/train/*\n",
    "!mkdir ../data/pollen23e_aug/valid\n",
    "!mkdir ../data/pollen23e_aug/train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "descrição-metodologia"
    ]
   },
   "source": [
    "Os experimentos foram executados com a técnica de Ajuste Fino - AF, em que os pesos dos modelos foram inicializados com a rede já previamente treinados no banco de imagens ImageNet. Para todas arquiteturas usamos o método de otimização gradiente descendente estocástico com a taxa de aprendizado de $10^{-3}$ com momento de $0.9$, e ao final de todo modelo conectamos uma camada achatada e uma camada totalmente conectada para predição com ativação Softmax. \n",
    "\n",
    "Em todos os modelos, dado limitação de tempo, exploramos $10$ épocas de treinamento, com tamanho de batch de $128$. No melhor modelo analisamos o seu comportamento em $100$ épocas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InceptionResNetV2',\n",
       " 'InceptionV3',\n",
       " 'MobileNet',\n",
       " 'MobileNetV2',\n",
       " 'NASNetMobile',\n",
       " 'ResNet50',\n",
       " 'VGG16',\n",
       " 'VGG19',\n",
       " 'Xception']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": [
     "train_model",
     "compile_models"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 validated image filenames.\n",
      "Found 160 validated image filenames.\n",
      "Found 161 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brain/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 8s 0us/step\n",
      "Epoch 1/30\n",
      "29/30 [============================>.] - ETA: 1s - loss: 0.3917 - acc: 0.8921\n",
      "Epoch 00001: val_loss improved from inf to 0.23832, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 241s 8s/step - loss: 0.3877 - acc: 0.8937 - val_loss: 0.2383 - val_acc: 0.9369\n",
      "Epoch 2/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9430\n",
      "Epoch 00002: val_loss improved from 0.23832 to 0.18793, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1881 - acc: 0.9431 - val_loss: 0.1879 - val_acc: 0.9385\n",
      "Epoch 3/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9526\n",
      "Epoch 00003: val_loss improved from 0.18793 to 0.16334, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1434 - acc: 0.9527 - val_loss: 0.1633 - val_acc: 0.9473\n",
      "Epoch 4/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9579\n",
      "Epoch 00004: val_loss improved from 0.16334 to 0.13355, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1205 - acc: 0.9576 - val_loss: 0.1335 - val_acc: 0.9538\n",
      "Epoch 5/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9610\n",
      "Epoch 00005: val_loss improved from 0.13355 to 0.12539, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1064 - acc: 0.9613 - val_loss: 0.1254 - val_acc: 0.9561\n",
      "Epoch 6/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9632\n",
      "Epoch 00006: val_loss improved from 0.12539 to 0.11686, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0983 - acc: 0.9633 - val_loss: 0.1169 - val_acc: 0.9611\n",
      "Epoch 7/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9702\n",
      "Epoch 00007: val_loss improved from 0.11686 to 0.10240, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0836 - acc: 0.9701 - val_loss: 0.1024 - val_acc: 0.9645\n",
      "Epoch 8/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9720\n",
      "Epoch 00008: val_loss improved from 0.10240 to 0.08975, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0727 - acc: 0.9723 - val_loss: 0.0897 - val_acc: 0.9672\n",
      "Epoch 9/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9747\n",
      "Epoch 00009: val_loss improved from 0.08975 to 0.08481, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0690 - acc: 0.9741 - val_loss: 0.0848 - val_acc: 0.9690\n",
      "Epoch 10/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9755\n",
      "Epoch 00010: val_loss improved from 0.08481 to 0.07320, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0635 - acc: 0.9756 - val_loss: 0.0732 - val_acc: 0.9740\n",
      "Epoch 11/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9778\n",
      "Epoch 00011: val_loss improved from 0.07320 to 0.07005, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0595 - acc: 0.9779 - val_loss: 0.0700 - val_acc: 0.9751\n",
      "Epoch 12/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9804\n",
      "Epoch 00012: val_loss did not improve from 0.07005\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0535 - acc: 0.9802 - val_loss: 0.0749 - val_acc: 0.9734\n",
      "Epoch 13/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9826\n",
      "Epoch 00013: val_loss did not improve from 0.07005\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0500 - acc: 0.9826 - val_loss: 0.0762 - val_acc: 0.9739\n",
      "Epoch 14/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9817\n",
      "Epoch 00014: val_loss did not improve from 0.07005\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0488 - acc: 0.9816 - val_loss: 0.0887 - val_acc: 0.9710\n",
      "Epoch 15/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9814\n",
      "Epoch 00015: val_loss did not improve from 0.07005\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0476 - acc: 0.9816 - val_loss: 0.0891 - val_acc: 0.9698\n",
      "Epoch 16/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9840\n",
      "Epoch 00016: val_loss did not improve from 0.07005\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0447 - acc: 0.9838 - val_loss: 0.0723 - val_acc: 0.9757\n",
      "Epoch 17/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9844\n",
      "Epoch 00017: val_loss improved from 0.07005 to 0.06270, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0412 - acc: 0.9844 - val_loss: 0.0627 - val_acc: 0.9779\n",
      "Epoch 18/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9859\n",
      "Epoch 00018: val_loss improved from 0.06270 to 0.05802, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0396 - acc: 0.9860 - val_loss: 0.0580 - val_acc: 0.9793\n",
      "Epoch 19/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9870\n",
      "Epoch 00019: val_loss improved from 0.05802 to 0.05236, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0348 - acc: 0.9868 - val_loss: 0.0524 - val_acc: 0.9806\n",
      "Epoch 20/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9886\n",
      "Epoch 00020: val_loss did not improve from 0.05236\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0331 - acc: 0.9887 - val_loss: 0.0529 - val_acc: 0.9802\n",
      "Epoch 21/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9868\n",
      "Epoch 00021: val_loss improved from 0.05236 to 0.04920, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0353 - acc: 0.9867 - val_loss: 0.0492 - val_acc: 0.9817\n",
      "Epoch 22/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9884\n",
      "Epoch 00022: val_loss did not improve from 0.04920\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0325 - acc: 0.9883 - val_loss: 0.0509 - val_acc: 0.9821\n",
      "Epoch 23/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9884\n",
      "Epoch 00023: val_loss improved from 0.04920 to 0.04737, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0307 - acc: 0.9884 - val_loss: 0.0474 - val_acc: 0.9834\n",
      "Epoch 24/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9893\n",
      "Epoch 00024: val_loss improved from 0.04737 to 0.04159, saving model to ../checkpoints_multi/ResNet50\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0280 - acc: 0.9894 - val_loss: 0.0416 - val_acc: 0.9847\n",
      "Epoch 25/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9901\n",
      "Epoch 00025: val_loss did not improve from 0.04159\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0274 - acc: 0.9901 - val_loss: 0.0499 - val_acc: 0.9821\n",
      "Epoch 26/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9882\n",
      "Epoch 00026: val_loss did not improve from 0.04159\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0334 - acc: 0.9881 - val_loss: 0.0456 - val_acc: 0.9831\n",
      "Epoch 27/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9885\n",
      "Epoch 00027: val_loss did not improve from 0.04159\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0319 - acc: 0.9881 - val_loss: 0.0418 - val_acc: 0.9853\n",
      "Epoch 28/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9919\n",
      "Epoch 00028: val_loss did not improve from 0.04159\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.0225 - acc: 0.9919 - val_loss: 0.0465 - val_acc: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9919\n",
      "Epoch 00029: val_loss did not improve from 0.04159\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0235 - acc: 0.9919 - val_loss: 0.0433 - val_acc: 0.9839\n",
      "Epoch 30/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9914\n",
      "Epoch 00030: val_loss did not improve from 0.04159\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0241 - acc: 0.9915 - val_loss: 0.0474 - val_acc: 0.9830\n",
      "Found 480 validated image filenames.\n",
      "Found 160 validated image filenames.\n",
      "Found 161 validated image filenames.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 4s 0us/step\n",
      "Epoch 1/30\n",
      "29/30 [============================>.] - ETA: 2s - loss: 0.4290 - acc: 0.8936\n",
      "Epoch 00001: val_loss improved from inf to 0.20863, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 112s 4s/step - loss: 0.4221 - acc: 0.8953 - val_loss: 0.2086 - val_acc: 0.9452\n",
      "Epoch 2/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9452\n",
      "Epoch 00002: val_loss improved from 0.20863 to 0.20325, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.2071 - acc: 0.9452 - val_loss: 0.2033 - val_acc: 0.9452\n",
      "Epoch 3/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9452\n",
      "Epoch 00003: val_loss improved from 0.20325 to 0.19733, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.2021 - acc: 0.9452 - val_loss: 0.1973 - val_acc: 0.9452\n",
      "Epoch 4/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9458\n",
      "Epoch 00004: val_loss improved from 0.19733 to 0.18226, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1920 - acc: 0.9458 - val_loss: 0.1823 - val_acc: 0.9465\n",
      "Epoch 5/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1771 - acc: 0.9466\n",
      "Epoch 00005: val_loss improved from 0.18226 to 0.16677, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1779 - acc: 0.9465 - val_loss: 0.1668 - val_acc: 0.9467\n",
      "Epoch 6/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9466\n",
      "Epoch 00006: val_loss did not improve from 0.16677\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1648 - acc: 0.9464 - val_loss: 0.1678 - val_acc: 0.9482\n",
      "Epoch 7/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9464\n",
      "Epoch 00007: val_loss improved from 0.16677 to 0.15847, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1569 - acc: 0.9466 - val_loss: 0.1585 - val_acc: 0.9470\n",
      "Epoch 8/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9489\n",
      "Epoch 00008: val_loss improved from 0.15847 to 0.14462, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1494 - acc: 0.9488 - val_loss: 0.1446 - val_acc: 0.9464\n",
      "Epoch 9/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9494\n",
      "Epoch 00009: val_loss improved from 0.14462 to 0.13459, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1413 - acc: 0.9497 - val_loss: 0.1346 - val_acc: 0.9501\n",
      "Epoch 10/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9506\n",
      "Epoch 00010: val_loss improved from 0.13459 to 0.13187, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1361 - acc: 0.9507 - val_loss: 0.1319 - val_acc: 0.9517\n",
      "Epoch 11/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9516\n",
      "Epoch 00011: val_loss improved from 0.13187 to 0.11941, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1294 - acc: 0.9519 - val_loss: 0.1194 - val_acc: 0.9554\n",
      "Epoch 12/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9550\n",
      "Epoch 00012: val_loss did not improve from 0.11941\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1206 - acc: 0.9547 - val_loss: 0.1250 - val_acc: 0.9552\n",
      "Epoch 13/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9571\n",
      "Epoch 00013: val_loss improved from 0.11941 to 0.11516, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1112 - acc: 0.9571 - val_loss: 0.1152 - val_acc: 0.9549\n",
      "Epoch 14/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9590\n",
      "Epoch 00014: val_loss did not improve from 0.11516\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1068 - acc: 0.9590 - val_loss: 0.1215 - val_acc: 0.9543\n",
      "Epoch 15/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9578\n",
      "Epoch 00015: val_loss improved from 0.11516 to 0.10789, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1102 - acc: 0.9576 - val_loss: 0.1079 - val_acc: 0.9576\n",
      "Epoch 16/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9607\n",
      "Epoch 00016: val_loss improved from 0.10789 to 0.09970, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0998 - acc: 0.9607 - val_loss: 0.0997 - val_acc: 0.9603\n",
      "Epoch 17/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9621\n",
      "Epoch 00017: val_loss did not improve from 0.09970\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0950 - acc: 0.9618 - val_loss: 0.1006 - val_acc: 0.9605\n",
      "Epoch 18/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9619\n",
      "Epoch 00018: val_loss improved from 0.09970 to 0.09246, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0977 - acc: 0.9620 - val_loss: 0.0925 - val_acc: 0.9641\n",
      "Epoch 19/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9642\n",
      "Epoch 00019: val_loss improved from 0.09246 to 0.09080, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0885 - acc: 0.9645 - val_loss: 0.0908 - val_acc: 0.9638\n",
      "Epoch 20/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9654\n",
      "Epoch 00020: val_loss improved from 0.09080 to 0.08559, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0893 - acc: 0.9656 - val_loss: 0.0856 - val_acc: 0.9644\n",
      "Epoch 21/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9688\n",
      "Epoch 00021: val_loss did not improve from 0.08559\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0800 - acc: 0.9689 - val_loss: 0.0889 - val_acc: 0.9653\n",
      "Epoch 22/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9706\n",
      "Epoch 00022: val_loss improved from 0.08559 to 0.07694, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0730 - acc: 0.9709 - val_loss: 0.0769 - val_acc: 0.9687\n",
      "Epoch 23/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9722\n",
      "Epoch 00023: val_loss did not improve from 0.07694\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0696 - acc: 0.9725 - val_loss: 0.0803 - val_acc: 0.9677\n",
      "Epoch 24/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9694\n",
      "Epoch 00024: val_loss did not improve from 0.07694\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0775 - acc: 0.9691 - val_loss: 0.0862 - val_acc: 0.9660\n",
      "Epoch 25/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9724\n",
      "Epoch 00025: val_loss improved from 0.07694 to 0.07102, saving model to ../checkpoints_multi/VGG16\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0714 - acc: 0.9724 - val_loss: 0.0710 - val_acc: 0.9727\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/30 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9728\n",
      "Epoch 00026: val_loss did not improve from 0.07102\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.0660 - acc: 0.9730 - val_loss: 0.0807 - val_acc: 0.9707\n",
      "Epoch 27/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9727\n",
      "Epoch 00027: val_loss did not improve from 0.07102\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0705 - acc: 0.9727 - val_loss: 0.0738 - val_acc: 0.9709\n",
      "Epoch 28/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9723\n",
      "Epoch 00028: val_loss did not improve from 0.07102\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0706 - acc: 0.9724 - val_loss: 0.0854 - val_acc: 0.9679\n",
      "Epoch 29/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9727\n",
      "Epoch 00029: val_loss did not improve from 0.07102\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0686 - acc: 0.9730 - val_loss: 0.0721 - val_acc: 0.9712\n",
      "Epoch 30/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9740\n",
      "Epoch 00030: val_loss did not improve from 0.07102\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0660 - acc: 0.9741 - val_loss: 0.0721 - val_acc: 0.9728\n",
      "Found 480 validated image filenames.\n",
      "Found 160 validated image filenames.\n",
      "Found 161 validated image filenames.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 19s 0us/step\n",
      "Epoch 1/30\n",
      "29/30 [============================>.] - ETA: 2s - loss: 0.3962 - acc: 0.8990\n",
      "Epoch 00001: val_loss improved from inf to 0.20693, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 124s 4s/step - loss: 0.3901 - acc: 0.9005 - val_loss: 0.2069 - val_acc: 0.9452\n",
      "Epoch 2/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9452\n",
      "Epoch 00002: val_loss improved from 0.20693 to 0.19998, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.2043 - acc: 0.9452 - val_loss: 0.2000 - val_acc: 0.9452\n",
      "Epoch 3/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9452\n",
      "Epoch 00003: val_loss improved from 0.19998 to 0.19405, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1984 - acc: 0.9453 - val_loss: 0.1941 - val_acc: 0.9463\n",
      "Epoch 4/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9464\n",
      "Epoch 00004: val_loss improved from 0.19405 to 0.18099, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1883 - acc: 0.9465 - val_loss: 0.1810 - val_acc: 0.9467\n",
      "Epoch 5/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9471\n",
      "Epoch 00005: val_loss improved from 0.18099 to 0.16567, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1764 - acc: 0.9470 - val_loss: 0.1657 - val_acc: 0.9474\n",
      "Epoch 6/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9477\n",
      "Epoch 00006: val_loss improved from 0.16567 to 0.16205, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1639 - acc: 0.9474 - val_loss: 0.1621 - val_acc: 0.9469\n",
      "Epoch 7/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9487\n",
      "Epoch 00007: val_loss improved from 0.16205 to 0.14722, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1507 - acc: 0.9487 - val_loss: 0.1472 - val_acc: 0.9499\n",
      "Epoch 8/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9495\n",
      "Epoch 00008: val_loss improved from 0.14722 to 0.14002, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1423 - acc: 0.9498 - val_loss: 0.1400 - val_acc: 0.9509\n",
      "Epoch 9/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9514\n",
      "Epoch 00009: val_loss improved from 0.14002 to 0.12928, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1314 - acc: 0.9512 - val_loss: 0.1293 - val_acc: 0.9532\n",
      "Epoch 10/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9526\n",
      "Epoch 00010: val_loss improved from 0.12928 to 0.12325, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1272 - acc: 0.9525 - val_loss: 0.1233 - val_acc: 0.9542\n",
      "Epoch 11/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9545\n",
      "Epoch 00011: val_loss improved from 0.12325 to 0.10948, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1171 - acc: 0.9543 - val_loss: 0.1095 - val_acc: 0.9562\n",
      "Epoch 12/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9559\n",
      "Epoch 00012: val_loss improved from 0.10948 to 0.10891, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1140 - acc: 0.9561 - val_loss: 0.1089 - val_acc: 0.9579\n",
      "Epoch 13/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9566\n",
      "Epoch 00013: val_loss did not improve from 0.10891\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.1095 - acc: 0.9566 - val_loss: 0.1141 - val_acc: 0.9565\n",
      "Epoch 14/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9602\n",
      "Epoch 00014: val_loss improved from 0.10891 to 0.10769, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1025 - acc: 0.9602 - val_loss: 0.1077 - val_acc: 0.9573\n",
      "Epoch 15/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9604\n",
      "Epoch 00015: val_loss improved from 0.10769 to 0.08973, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0999 - acc: 0.9609 - val_loss: 0.0897 - val_acc: 0.9639\n",
      "Epoch 16/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9645\n",
      "Epoch 00016: val_loss did not improve from 0.08973\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0907 - acc: 0.9644 - val_loss: 0.0940 - val_acc: 0.9627\n",
      "Epoch 17/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9652\n",
      "Epoch 00017: val_loss did not improve from 0.08973\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0880 - acc: 0.9650 - val_loss: 0.0946 - val_acc: 0.9636\n",
      "Epoch 18/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9647\n",
      "Epoch 00018: val_loss did not improve from 0.08973\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0909 - acc: 0.9646 - val_loss: 0.0946 - val_acc: 0.9657\n",
      "Epoch 19/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9668\n",
      "Epoch 00019: val_loss did not improve from 0.08973\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0879 - acc: 0.9666 - val_loss: 0.0930 - val_acc: 0.9646\n",
      "Epoch 20/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9679\n",
      "Epoch 00020: val_loss improved from 0.08973 to 0.07666, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0815 - acc: 0.9679 - val_loss: 0.0767 - val_acc: 0.9700\n",
      "Epoch 21/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9681\n",
      "Epoch 00021: val_loss did not improve from 0.07666\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0821 - acc: 0.9685 - val_loss: 0.0812 - val_acc: 0.9682\n",
      "Epoch 22/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9695\n",
      "Epoch 00022: val_loss did not improve from 0.07666\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0762 - acc: 0.9694 - val_loss: 0.0844 - val_acc: 0.9681\n",
      "Epoch 23/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9725\n",
      "Epoch 00023: val_loss did not improve from 0.07666\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0746 - acc: 0.9723 - val_loss: 0.0882 - val_acc: 0.9655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9728\n",
      "Epoch 00024: val_loss did not improve from 0.07666\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0710 - acc: 0.9724 - val_loss: 0.0869 - val_acc: 0.9693\n",
      "Epoch 25/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9732\n",
      "Epoch 00025: val_loss did not improve from 0.07666\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0695 - acc: 0.9730 - val_loss: 0.0808 - val_acc: 0.9689\n",
      "Epoch 26/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9746\n",
      "Epoch 00026: val_loss improved from 0.07666 to 0.07643, saving model to ../checkpoints_multi/VGG19\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0643 - acc: 0.9748 - val_loss: 0.0764 - val_acc: 0.9712\n",
      "Epoch 27/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9764\n",
      "Epoch 00027: val_loss did not improve from 0.07643\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0612 - acc: 0.9762 - val_loss: 0.0894 - val_acc: 0.9677\n",
      "Epoch 28/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9732\n",
      "Epoch 00028: val_loss did not improve from 0.07643\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0690 - acc: 0.9731 - val_loss: 0.0791 - val_acc: 0.9712\n",
      "Epoch 29/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9771\n",
      "Epoch 00029: val_loss did not improve from 0.07643\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0592 - acc: 0.9772 - val_loss: 0.0832 - val_acc: 0.9687\n",
      "Epoch 30/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9774\n",
      "Epoch 00030: val_loss did not improve from 0.07643\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0604 - acc: 0.9773 - val_loss: 0.0768 - val_acc: 0.9702\n",
      "Found 480 validated image filenames.\n",
      "Found 160 validated image filenames.\n",
      "Found 161 validated image filenames.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 5s 0us/step\n",
      "Epoch 1/30\n",
      "29/30 [============================>.] - ETA: 2s - loss: 0.3289 - acc: 0.8831\n",
      "Epoch 00001: val_loss improved from inf to 0.22312, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 261s 9s/step - loss: 0.3252 - acc: 0.8852 - val_loss: 0.2231 - val_acc: 0.9447\n",
      "Epoch 2/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9452\n",
      "Epoch 00002: val_loss improved from 0.22312 to 0.21001, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.2079 - acc: 0.9452 - val_loss: 0.2100 - val_acc: 0.9454\n",
      "Epoch 3/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9461\n",
      "Epoch 00003: val_loss improved from 0.21001 to 0.19751, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1911 - acc: 0.9461 - val_loss: 0.1975 - val_acc: 0.9458\n",
      "Epoch 4/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9472\n",
      "Epoch 00004: val_loss improved from 0.19751 to 0.18136, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1775 - acc: 0.9472 - val_loss: 0.1814 - val_acc: 0.9484\n",
      "Epoch 5/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9486\n",
      "Epoch 00005: val_loss improved from 0.18136 to 0.16903, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1660 - acc: 0.9485 - val_loss: 0.1690 - val_acc: 0.9493\n",
      "Epoch 6/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9504\n",
      "Epoch 00006: val_loss improved from 0.16903 to 0.15958, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1553 - acc: 0.9503 - val_loss: 0.1596 - val_acc: 0.9512\n",
      "Epoch 7/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9512\n",
      "Epoch 00007: val_loss improved from 0.15958 to 0.14843, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1465 - acc: 0.9512 - val_loss: 0.1484 - val_acc: 0.9530\n",
      "Epoch 8/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9528\n",
      "Epoch 00008: val_loss improved from 0.14843 to 0.13944, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1386 - acc: 0.9528 - val_loss: 0.1394 - val_acc: 0.9556\n",
      "Epoch 9/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9550\n",
      "Epoch 00009: val_loss improved from 0.13944 to 0.12867, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1330 - acc: 0.9550 - val_loss: 0.1287 - val_acc: 0.9562\n",
      "Epoch 10/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9555\n",
      "Epoch 00010: val_loss improved from 0.12867 to 0.12385, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1261 - acc: 0.9553 - val_loss: 0.1239 - val_acc: 0.9578\n",
      "Epoch 11/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9575\n",
      "Epoch 00011: val_loss improved from 0.12385 to 0.11789, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1208 - acc: 0.9576 - val_loss: 0.1179 - val_acc: 0.9594\n",
      "Epoch 12/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9584\n",
      "Epoch 00012: val_loss improved from 0.11789 to 0.11446, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1164 - acc: 0.9587 - val_loss: 0.1145 - val_acc: 0.9612\n",
      "Epoch 13/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9614\n",
      "Epoch 00013: val_loss improved from 0.11446 to 0.10787, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.1103 - acc: 0.9614 - val_loss: 0.1079 - val_acc: 0.9627\n",
      "Epoch 14/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9620\n",
      "Epoch 00014: val_loss improved from 0.10787 to 0.10412, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.1051 - acc: 0.9618 - val_loss: 0.1041 - val_acc: 0.9642\n",
      "Epoch 15/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9628\n",
      "Epoch 00015: val_loss improved from 0.10412 to 0.09999, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.1019 - acc: 0.9629 - val_loss: 0.1000 - val_acc: 0.9647\n",
      "Epoch 16/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9645\n",
      "Epoch 00016: val_loss improved from 0.09999 to 0.09523, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0995 - acc: 0.9645 - val_loss: 0.0952 - val_acc: 0.9666\n",
      "Epoch 17/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9680\n",
      "Epoch 00017: val_loss did not improve from 0.09523\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0928 - acc: 0.9679 - val_loss: 0.0970 - val_acc: 0.9667\n",
      "Epoch 18/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9672\n",
      "Epoch 00018: val_loss improved from 0.09523 to 0.08839, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 38s 1s/step - loss: 0.0930 - acc: 0.9673 - val_loss: 0.0884 - val_acc: 0.9690\n",
      "Epoch 19/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9688\n",
      "Epoch 00019: val_loss did not improve from 0.08839\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0879 - acc: 0.9690 - val_loss: 0.0889 - val_acc: 0.9700\n",
      "Epoch 20/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9700\n",
      "Epoch 00020: val_loss improved from 0.08839 to 0.08606, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0862 - acc: 0.9698 - val_loss: 0.0861 - val_acc: 0.9702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9697\n",
      "Epoch 00021: val_loss improved from 0.08606 to 0.08531, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0830 - acc: 0.9696 - val_loss: 0.0853 - val_acc: 0.9703\n",
      "Epoch 22/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9721\n",
      "Epoch 00022: val_loss improved from 0.08531 to 0.08060, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0803 - acc: 0.9723 - val_loss: 0.0806 - val_acc: 0.9722\n",
      "Epoch 23/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9720\n",
      "Epoch 00023: val_loss improved from 0.08060 to 0.07861, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0759 - acc: 0.9725 - val_loss: 0.0786 - val_acc: 0.9735\n",
      "Epoch 24/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9753\n",
      "Epoch 00024: val_loss improved from 0.07861 to 0.07697, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0733 - acc: 0.9752 - val_loss: 0.0770 - val_acc: 0.9742\n",
      "Epoch 25/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9751\n",
      "Epoch 00025: val_loss improved from 0.07697 to 0.07594, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0725 - acc: 0.9749 - val_loss: 0.0759 - val_acc: 0.9741\n",
      "Epoch 26/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9748\n",
      "Epoch 00026: val_loss improved from 0.07594 to 0.07171, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0738 - acc: 0.9743 - val_loss: 0.0717 - val_acc: 0.9771\n",
      "Epoch 27/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9731\n",
      "Epoch 00027: val_loss improved from 0.07171 to 0.07038, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 36s 1s/step - loss: 0.0729 - acc: 0.9737 - val_loss: 0.0704 - val_acc: 0.9771\n",
      "Epoch 28/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9761\n",
      "Epoch 00028: val_loss improved from 0.07038 to 0.06732, saving model to ../checkpoints_multi/Xception\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.0680 - acc: 0.9763 - val_loss: 0.0673 - val_acc: 0.9771\n",
      "Epoch 29/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9767\n",
      "Epoch 00029: val_loss did not improve from 0.06732\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0667 - acc: 0.9767 - val_loss: 0.0683 - val_acc: 0.9782\n",
      "Epoch 30/30\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9764\n",
      "Epoch 00030: val_loss did not improve from 0.06732\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0687 - acc: 0.9765 - val_loss: 0.0689 - val_acc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "for enum, model in enumerate(models):\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "                            dataframe = train,\n",
    "                            directory =   '../data/pollen23e_split_multi/train',\n",
    "                            x_col=\"caminho\",\n",
    "                            y_col=columns,\n",
    "                            target_size = (299,299),\n",
    "                            batch_size = batch_size,\n",
    "                            save_to_dir = '../data/pollen23e_aug_multi/train',\n",
    "                            save_prefix='aug', \n",
    "                            save_format='png',\n",
    "                            class_mode = \"other\",\n",
    "                            follow_links = True,\n",
    "                            seed = seed)\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_dataframe(\n",
    "                            dataframe = val,\n",
    "                            directory =   '../data/pollen23e_split_multi/val',\n",
    "                            x_col=\"caminho\",\n",
    "                            y_col=columns,\n",
    "                            class_mode = \"other\",\n",
    "                            target_size = (299,299),\n",
    "                            save_to_dir = '../data/pollen23e_aug_multi/val',\n",
    "                            save_prefix='aug', \n",
    "                            save_format='png',\n",
    "                            follow_links = True,\n",
    "                            seed = seed)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Save the model according to the conditions\n",
    "    checkpoint = ModelCheckpoint(\"../checkpoints_multi/\"+models_name[enum], \n",
    "                                 monitor='val_loss', verbose=1, \n",
    "                                 save_weights_only=False, \n",
    "                                 mode='auto', \n",
    "                                 save_best_only=True)\n",
    "    \n",
    "    model = models[enum](weights     = \"imagenet\", \n",
    "                         include_top = False, \n",
    "                         input_shape = (img_width, img_height, 3))\n",
    "    \n",
    "    #Adicionando um camada adicional\n",
    "    x = model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(len(columns),  activation='sigmoid')(x)\n",
    "    \n",
    "    # Camada final\n",
    "    model = Model(model.input,predictions)\n",
    "    # compile the model\n",
    "    model.compile(loss = \"binary_crossentropy\", \n",
    "                  optimizer = optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    \n",
    "    history_acc = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch = train_generator.samples/batch_size,\n",
    "                epochs = epochs,\n",
    "                callbacks = [checkpoint],\n",
    "                validation_data = validation_generator,\n",
    "                validation_steps = validation_generator.samples/batch_size)\n",
    "    \n",
    "    model.save(\"../models/\"+models_name[enum]+\".h5\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-754d59a7f97d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "test_mode"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-31d4338264ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m test_generator = test_datagen.flow_from_dataframe(\n\u001b[1;32m      3\u001b[0m                             \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0;34m'../data/pollen23e_split_multi/test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"caminho\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "                            dataframe = test,\n",
    "                            directory =   '../data/pollen23e_split_multi/test',\n",
    "                            x_col=\"caminho\",\n",
    "                            y_col=columns,\n",
    "                            save_to_dir = '../data/pollen23e_aug_multi/test',\n",
    "                            target_size = (299,299),\n",
    "                            batch_size = batch_size,\n",
    "                            class_mode = 'other',\n",
    "                            follow_links = True,\n",
    "                            seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "metrics"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão <a id='Conclusao'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.google.com/search?q=reprodutibility+in+computer+science+jupyter&oq=reprodutibility+in+computer+science+jupyter&aqs=chrome..69i57j33.9207j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "\n",
    "https://keras.io/applications/#resnet\n",
    "\n",
    "https://github.com/jupyter-guide/ten-rules-jupyter/blob/e7b184c4949d164ce12eb5fdfbc8c8cd487b8a23/example2/0-Workflow.ipynb\n",
    "\n",
    "https://github.com/nteract/papermill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Referências"
    ]
   },
   "source": [
    "## Referências\n",
    "\n",
    "- Gonçalves, Ariadne Barbosa, et al. [\"Feature extraction and machine learning for the classification of Brazilian Savannah pollen grains.\"](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157044) PloS one 11.6 (2016): e0157044.\n",
    "\n",
    "- Navares, Ricardo, and José Luis Aznarte. [\"Geographical Imputation of Missing Poaceae Pollen Data via Convolutional Neural Networks.\"](https://www.mdpi.com/2073-4433/10/11/717) Atmosphere 10.11 (2019): 717.\n",
    "\n",
    "- Menad, Hanane, Farah Ben-Naoum, and Abdelmalek Amine. [\"A Thresholding Approach for Pollen Detection in Images Based on Simulated Annealing Algorithm.\"](https://www.igi-global.com/article/a-thresholding-approach-for-pollen-detection-in-images-based-on-simulated-annealing-algorithm/237182) International Journal of Agricultural and Environmental Information Systems (IJAEIS) 10.4 (2019): 18-36.\n",
    "\n",
    "- Gallardo-Caballero, Ramón, et al. [\"Precise Pollen Grain Detection in Bright Field Microscopy Using Deep Learning Techniques.\"](https://www.mdpi.com/1424-8220/19/16/3583) Sensors 19.16 (2019): 3583.\n",
    "\n",
    "- Vizgarra, Cristian G., Informaticas Avanzadas, and Jorge Gotay Sardiñas. [\"Advances in the Classification of Pollen Grains Images Obtained from Honey Samples of Tetragonisca angustula in the Province of Chaco, Argentina.\"](https://ijisrt.com/wp-content/uploads/2019/07/IJISRT19JU564.pdf)\n",
    "\n",
    "- de Geus, André R., et al. [\"Large-scale Pollen Recognition with Deep Learning.\"](https://ieeexplore.ieee.org/abstract/document/8902735) 2019 27th European Signal Processing Conference (EUSIPCO). IEEE, 2019.\n",
    "\n",
    "- Allen, G. P., et al. [\"Machine vision for automated optical recognition and classification of pollen grains or other singulated microscopic objects.\"](https://ieeexplore.ieee.org/abstract/document/4749537/) 2008 15th International Conference on Mechatronics and Machine Vision in Practice. IEEE, 2008.\n",
    "\n",
    "- Menad, Hanane, Ben-Naoum, Farah, & Amine, Abdelmalek (2019). [\"Deep Convolutional Neural Network for Pollen Grains Classification\"](http://ceur-ws.org/Vol-2351/paper_34.pdf). In _JERI_.\n",
    "\n",
    "- Nguyen, Nhat Rich, Matina Donalson-Matasci, and Min C. Shin. [\"Improving pollen classification with less training effort.\"](https://ieeexplore.ieee.org/abstract/document/6475049/) 2013 IEEE Workshop on Applications of Computer Vision (WACV). IEEE, 2013.\n",
    "\n",
    "- Sevillano, Víctor, and José L. Aznarte. [\"Improving classification of pollen grain images of the POLEN23E dataset through three different applications of deep learning convolutional neural networks.\"](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201807) PloS one 13.9 (2018): e0201807.\n",
    "\n",
    "- Oteros, J., et al. [\"Year clustering analysis for modelling olive flowering phenology.\"](https://link.springer.com/article/10.1007/s00484-012-0581-3) International journal of biometeorology 57.4 (2013): 545-555.\n",
    "\n",
    "- Holt, K., et al. [\"Progress towards an automated trainable pollen location and classifier system for use in the palynology laboratory.\"](https://www.sciencedirect.com/science/article/pii/S0034666711001205) Review of Palaeobotany and Palynology 167.3-4 (2011): 175-183.\n",
    "\n",
    "- Valan, Miroslav, et al. [\"Automated Taxonomic Identification of Insects with Expert-Level Accuracy Using Effective Feature Transfer from Convolutional Networks.\"](https://academic.oup.com/sysbio/article/68/6/876/5368535) Systematic biology (2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biblioteca para impressão do versionamento das bibliotecas importadas. Importante para reprodutibilidade do trabalho\n",
    "%load_ext watermark\n",
    "print(\"\\nSistema\\n\")\n",
    "%watermark\n",
    "print(\"\\nBibliotecas\\n\")\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "name": "Entrega_0-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
